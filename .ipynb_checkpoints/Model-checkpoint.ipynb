{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Libraries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print('Loaded Libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "      <th># of Perps</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>total_num_hurt_killed</th>\n",
       "      <th>Australasia &amp; Oceania</th>\n",
       "      <th>Central America &amp; Caribbean</th>\n",
       "      <th>Central Asia</th>\n",
       "      <th>East Asia</th>\n",
       "      <th>Eastern Europe</th>\n",
       "      <th>Middle East &amp; North Africa</th>\n",
       "      <th>...</th>\n",
       "      <th>Catastrophic Damage (greater 1B USD)</th>\n",
       "      <th>Major Damage (greater 1M USD but less 1B USD)</th>\n",
       "      <th>Minor Damage (less 1M USD)</th>\n",
       "      <th>Chemical</th>\n",
       "      <th>Explosives/Bombs/Dynamite</th>\n",
       "      <th>Firearms</th>\n",
       "      <th>Incendiary</th>\n",
       "      <th>Melee</th>\n",
       "      <th>Sabotage Equipment</th>\n",
       "      <th>Vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Success  # of Perps  Suicide  total_num_hurt_killed  Australasia & Oceania  \\\n",
       "0        1         200        0                      4                      0   \n",
       "1        1           1        0                     39                      0   \n",
       "2        1           4        0                      0                      0   \n",
       "3        1           4        0                      0                      0   \n",
       "4        1           1        0                      0                      0   \n",
       "\n",
       "   Central America & Caribbean  Central Asia  East Asia  Eastern Europe  \\\n",
       "0                            0             0          0               0   \n",
       "1                            0             0          0               0   \n",
       "2                            0             0          0               0   \n",
       "3                            0             0          0               0   \n",
       "4                            0             0          0               0   \n",
       "\n",
       "   Middle East & North Africa    ...     Catastrophic Damage (greater 1B USD)  \\\n",
       "0                           0    ...                                        0   \n",
       "1                           0    ...                                        0   \n",
       "2                           0    ...                                        0   \n",
       "3                           0    ...                                        0   \n",
       "4                           0    ...                                        0   \n",
       "\n",
       "   Major Damage (greater 1M USD but less 1B USD)  Minor Damage (less 1M USD)  \\\n",
       "0                                              0                           1   \n",
       "1                                              0                           1   \n",
       "2                                              0                           1   \n",
       "3                                              0                           1   \n",
       "4                                              0                           1   \n",
       "\n",
       "   Chemical  Explosives/Bombs/Dynamite  Firearms  Incendiary  Melee  \\\n",
       "0         0                          0         1           0      0   \n",
       "1         0                          1         0           0      0   \n",
       "2         0                          1         0           0      0   \n",
       "3         0                          0         1           0      0   \n",
       "4         0                          1         0           0      0   \n",
       "\n",
       "   Sabotage Equipment  Vehicle   \n",
       "0                   0         0  \n",
       "1                   0         0  \n",
       "2                   0         0  \n",
       "3                   0         0  \n",
       "4                   0         0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"cleaned_data.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "train_data.drop('nkill', 1, inplace=True)   \n",
    "train_data.drop('nwound', 1, inplace=True)\n",
    "train_data.drop('propvalue', 1, inplace=True)\n",
    "train_data.drop('iyear', 1, inplace=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 53)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train_data\n",
    "\n",
    "# Split into training and validation sets\n",
    "train, validation = train_test_split(train_data, \n",
    "                                        shuffle = True,\n",
    "                                        test_size=0.4,\n",
    "                                        random_state=42\n",
    "                                        )\n",
    "\n",
    "\n",
    "validation, test = train_test_split(validation, \n",
    "                                        shuffle = True,\n",
    "                                        test_size=0.5,\n",
    "                                        random_state=42\n",
    "                                        )\n",
    "\n",
    "\n",
    "\n",
    "# Split data into input and outputs\n",
    "X_train = train.loc[:, train.columns != 'total_num_hurt_killed']\n",
    "y_train = train['total_num_hurt_killed']\n",
    "\n",
    "X_val = validation.loc[:, validation.columns != 'total_num_hurt_killed']\n",
    "y_val = validation['total_num_hurt_killed']\n",
    "\n",
    "X_test = validation.loc[:, test.columns != 'total_num_hurt_killed']\n",
    "y_test = test['total_num_hurt_killed']\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotting_feature(feature_importances, class_name):\n",
    "\n",
    "\n",
    "#     zipped = zip(X_train, feature_importances)\n",
    "    \n",
    "    final = [x for x in zip(X_train, feature_importances)]\n",
    "    final.sort(key = lambda final: final[1])\n",
    "    plt.rcParams[\"figure.figsize\"] = [7,12]\n",
    "    plt.barh([x[0] for x in final], [x[1] for x in final])\n",
    "    plt.title(\"Most Important Features For: \" + str(class_name))\n",
    "    # plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "    # plt.bar(range(len(mens_model.feature_importances_)), mens_model.feature_importances_)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.bar(range(len(temp.feature_importances_)), temp.feature_importances_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "LinearRegression\n",
      "****Results****\n",
      "MSE: 536.9301499306235\n",
      "RMSE: 23.171753277009998\n",
      "R^2: 0.2323677937701668\n",
      "Adj R^2: 0.18675735999193677\n",
      "==============================\n",
      "KNeighborsRegressor\n",
      "****Results****\n",
      "MSE: 632.6034672304439\n",
      "RMSE: 25.1516096349805\n",
      "R^2: 0.09558665073754447\n",
      "Adj R^2: 0.04184908626342998\n",
      "==============================\n",
      "KNeighborsRegressor\n",
      "****Results****\n",
      "MSE: 529.4712685720973\n",
      "RMSE: 23.01024268824858\n",
      "R^2: 0.24303152266300676\n",
      "Adj R^2: 0.19805469609477733\n",
      "==============================\n",
      "DecisionTreeRegressor\n",
      "****Results****\n",
      "MSE: 597.7321113476296\n",
      "RMSE: 24.44856051688176\n",
      "R^2: 0.14544113526222469\n",
      "Adj R^2: 0.09466577670717746\n",
      "==============================\n",
      "GradientBoostingRegressor\n",
      "****Results****\n",
      "MSE: 520.3073262612348\n",
      "RMSE: 22.81024608068126\n",
      "R^2: 0.2561329237572817\n",
      "Adj R^2: 0.2119345436666269\n",
      "==============================\n",
      "GradientBoostingRegressor\n",
      "****Results****\n",
      "MSE: 515.1688902095051\n",
      "RMSE: 22.697332226706845\n",
      "R^2: 0.2634791847252491\n",
      "Adj R^2: 0.21971729771901394\n",
      "==============================\n",
      "RandomForestRegressor\n",
      "****Results****\n",
      "MSE: 540.137916125561\n",
      "RMSE: 23.240867370336268\n",
      "R^2: 0.22778175098302322\n",
      "Adj R^2: 0.18189882811542257\n",
      "==============================\n",
      "RandomForestRegressor\n",
      "****Results****\n",
      "MSE: 522.2885679637901\n",
      "RMSE: 22.853633583388664\n",
      "R^2: 0.25330040459365577\n",
      "Adj R^2: 0.2089337245975389\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "classifiers = [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(),\n",
    "    KNeighborsRegressor(17),\n",
    "    DecisionTreeRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    GradientBoostingRegressor(n_estimators=39, learning_rate=0.1, max_depth=3),\n",
    "    RandomForestRegressor(),\n",
    "    RandomForestRegressor(max_depth= 15, min_samples_leaf= 4, n_estimators= 53),\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Regressor\", \"MSE\", \"Adj R^2\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "        \n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_val)\n",
    "#     print(train_predictions)\n",
    "    mse = mean_squared_error(y_val, train_predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = float(r2_score(y_val, train_predictions))\n",
    "    adjr2 = 1 - ((1-r2) * (len(X_val)-1) / (len(X_val) - len(X_val.columns)-1))\n",
    "    print(\"MSE: {}\".format(mse))\n",
    "    print(\"RMSE: {}\".format(rmse))\n",
    "    print(\"R^2: {}\".format(r2))\n",
    "    print(\"Adj R^2: {}\".format(adjr2))\n",
    "    \n",
    "    \n",
    "#     try:\n",
    "# #         print(clf.feature_importances_)\n",
    "#         plotting_feature(clf.feature_importances_, name)\n",
    "#     except:\n",
    "#         print('HUH')\n",
    "#         continue\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, mse, r2]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822.2864693446089\n"
     ]
    }
   ],
   "source": [
    "all_zero = len(y_val) * [0]\n",
    "print(mean_squared_error(all_zero, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Code to Get OLS regression results\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# # X2 = sm.add_constant(X_train)\n",
    "# est = sm.OLS(y_train, X_train)\n",
    "# est2 = est.fit()\n",
    "# print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] grid search took 13.60 seconds\n",
      "{'n_neighbors': 17}\n",
      "1013.1274461034257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "############## TUNE KNN ###############\n",
    "\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 50, 1)}\n",
    "\n",
    "knnmodel = KNeighborsRegressor()\n",
    "model = GridSearchCV(estimator=knnmodel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error')\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# evaluate the best grid searched model on the testing data\n",
    "print(\"[INFO] grid search took {:.2f} seconds\".format(time.time() - start))\n",
    "print(model.best_params_)\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] grid search took 0.42 seconds\n",
      "{'n_estimators': 1}\n",
      "1754.889880801444\n"
     ]
    }
   ],
   "source": [
    "####### TUNE RF ###########\n",
    "\n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : np.arange(1, 2, 1)\n",
    "             \"max_depth\" : [1, 5, 10, 15, 20],\n",
    "#                \"min_samples_leaf\" : [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "RFmodel = RandomForestRegressor()\n",
    "model = GridSearchCV(estimator=RFmodel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error', verbose=0)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# evaluate the best grid searched model on the testing data\n",
    "print(\"[INFO] grid search took {:.2f} seconds\".format(time.time() - start))\n",
    "print(model.best_params_)\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-27d67f69a859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mXGBmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGBmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "####### TUNE XGB ###########\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : np.arange(1, 60, 1),\n",
    "             \"max_depth\" : np.arange(1,10),\n",
    "            \"learning_rate\": [0.1, 0.01]\n",
    "}\n",
    "\n",
    "#  (shrinkage).\n",
    "# n_estimators=100 (number of trees).\n",
    "# max_depth=3.\n",
    "# min_samples_split=2.\n",
    "# min_samples_leaf=1.\n",
    "# subsample=1.0.\n",
    "\n",
    "\n",
    "XGBmodel = GradientBoostingRegressor(random_state=42)\n",
    "model = GridSearchCV(estimator=XGBmodel, param_grid=param_grid, n_jobs=-1, cv=3, scoring='neg_mean_squared_error', verbose=0)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# evaluate the best grid searched model on the testing data\n",
    "print(\"[INFO] grid search took {:.2f} seconds\".format(time.time() - start))\n",
    "print(model.best_params_)\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(53, input_shape=(53,), activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(53, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(53, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning:\n",
      "\n",
      "Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 53)                2862      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 53)                2862      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 53)                2862      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 54        \n",
      "=================================================================\n",
      "Total params: 8,640\n",
      "Trainable params: 8,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1986 samples, validate on 852 samples\n",
      "Epoch 1/9\n",
      "1986/1986 [==============================] - 1s 387us/step - loss: 1397.7169 - acc: 0.1057 - val_loss: 1271.9233 - val_acc: 0.1127\n",
      "Epoch 2/9\n",
      "1986/1986 [==============================] - 1s 319us/step - loss: 1395.7301 - acc: 0.1057 - val_loss: 1271.7506 - val_acc: 0.1127\n",
      "Epoch 3/9\n",
      "1986/1986 [==============================] - 1s 476us/step - loss: 1395.6424 - acc: 0.1057 - val_loss: 1271.7088 - val_acc: 0.1127\n",
      "Epoch 4/9\n",
      "1986/1986 [==============================] - 1s 342us/step - loss: 1395.6144 - acc: 0.1057 - val_loss: 1271.6911 - val_acc: 0.1127\n",
      "Epoch 5/9\n",
      "1986/1986 [==============================] - 1s 463us/step - loss: 1395.6014 - acc: 0.1057 - val_loss: 1271.6819 - val_acc: 0.1127\n",
      "Epoch 6/9\n",
      "1986/1986 [==============================] - 1s 419us/step - loss: 1395.5943 - acc: 0.1057 - val_loss: 1271.6766 - val_acc: 0.1127\n",
      "Epoch 7/9\n",
      "1986/1986 [==============================] - 1s 444us/step - loss: 1395.5899 - acc: 0.1057 - val_loss: 1271.6732 - val_acc: 0.1127\n",
      "Epoch 8/9\n",
      "1986/1986 [==============================] - 1s 424us/step - loss: 1395.5870 - acc: 0.1057 - val_loss: 1271.6707 - val_acc: 0.1127\n",
      "Epoch 9/9\n",
      "1986/1986 [==============================] - 1s 428us/step - loss: 1395.5850 - acc: 0.1057 - val_loss: 1271.6690 - val_acc: 0.1127\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_1_input to have shape (None, 24) but got array with shape (946, 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-12fc2e612278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# PREDICTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mANN_m_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANN_model_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mANN_m_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1770\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1771\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1772\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_1_input to have shape (None, 24) but got array with shape (946, 53)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import losses\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(53, input_shape=(53,), init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(53, init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(53, init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# # 3\n",
    "import keras\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)\n",
    "\n",
    "# # 4\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=9, batch_size=10,  verbose=1, validation_split=0.3, callbacks=[tbCallBack])\n",
    "\n",
    "# PREDICTION\n",
    "ANN_m_prediction = ANN_model_m.predict(X_val)\n",
    "print(ANN_m_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
